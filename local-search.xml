<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Nginx</title>
    <link href="/2021/07/28/Nginx/"/>
    <url>/2021/07/28/Nginx/</url>
    
    <content type="html"><![CDATA[<h1 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h1><p><strong>1、 nginx 简介</strong></p><ul><li>（1） 什么是 nginx 和可以做什么事情</li><li>（2） 正向代理</li><li>（3） 反向代理</li><li>（4） 动静分离</li></ul><p>2、 Nginx 的安装</p><p>3、 Nginx 的常用命令和配置文件</p><p>4、 Nginx 配置实例 1 反向代理</p><p>5、 Nginx 配置实例 2 负载均衡</p><p>6、 Nginx 配置实例 3 动静分离  </p><p>7、 Nginx 的高可用集群</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">nginx</span> 配置主从模式<br><br>nginx 配置双主模式<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728155948176.png" alt="image-20210728155948176"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160004711.png" alt="image-20210728160004711"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160026260.png" alt="image-20210728160026260"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160041907.png" alt="image-20210728160041907"></p><p>Nginx安装：</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160225746.png" alt="image-20210728160225746"></p><p>1.解压opt目录下的pcer</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tar</span> -zxvf pcre-<span class="hljs-number">8</span>.<span class="hljs-number">37</span>.tar.gz<br></code></pre></td></tr></table></figure><p>2.进入pcre目录,依次执行以下命令</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gauss">./configure<br><span class="hljs-built_in">make</span> &amp;&amp; <span class="hljs-built_in">make</span> install<br>yum -y install <span class="hljs-built_in">make</span> zlib zlib-devel gcc-c++ libtool openssl openssl-devel<br></code></pre></td></tr></table></figure><p>3.安装nginx</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gauss">tar -zxvf nginx<span class="hljs-number">-1.12</span><span class="hljs-number">.2</span>tar.gz<br>进入nginx目录<br>./configure<br><span class="hljs-built_in">make</span> &amp;&amp; <span class="hljs-built_in">make</span> install<br></code></pre></td></tr></table></figure><p>4.进入/usr/local/nginx目录，输入./nginx即可启动</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160628645.png" alt="image-20210728160628645"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160658035.png" alt="image-20210728160658035"></p><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160846901.png" alt="image-20210728160846901"></p><p>1.在linux中开启tomcat</p><p>2.修改nginx的配置文件：</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728160937068.png" alt="image-20210728160937068"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728161003099.png" alt="image-20210728161003099"></p><h2 id="反向代理2："><a href="#反向代理2：" class="headerlink" title="反向代理2："></a>反向代理2：</h2><p><strong>1、实现效果</strong></p><p><strong>使用</strong> <strong>nginx</strong> <strong>反向代理，根据访问的路径跳转到不同端口的服务中</strong></p><p><strong>nginx</strong> <strong>监听端口为</strong> <strong>9001</strong>， </p><p><strong>访问</strong> <strong><a href="http://192.168.200.130:9001/edu/">http://192.168.200.130:9001/edu/</a></strong> <strong>直接跳转到</strong> <strong>127.0.0.1:8080</strong></p><p><strong>访问</strong> <strong>http:// 192.168.200.130:9001/vod/</strong> <strong>直接跳转到</strong> <strong>127.0.0.1:8081</strong> </p><p>1.在opt下创建tm8080和tm8081</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728161149982.png" alt="image-20210728161149982"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728161355552.png" alt="image-20210728161355552"></p><p>修改8081的配置：把80xx改为和8080不同的端口，然后启动两个tomcat</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728161453925.png" alt="image-20210728161453925"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728161527209.png" alt="image-20210728161527209"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728161536948.png" alt="image-20210728161536948"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728162838416.png" alt="image-20210728162838416"></p><p>保存，开放9001端口，重新加载nginx</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728163412713.png" alt="image-20210728163412713"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728163554878.png" alt="image-20210728163554878"></p><h2 id="负载均衡："><a href="#负载均衡：" class="headerlink" title="负载均衡："></a>负载均衡：</h2><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728165338263.png" alt="image-20210728165338263"></p><p>修改如下配置在conf下的nginx.conf中</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728165114113.png" alt="image-20210728165114113"></p><p>随着互联网信息的爆炸性增长，负载均衡（load balance）已经不再是一个很陌生的话题，顾名思义，负载均衡即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应足够快，给用户很好的体验。快速增长的访问量和数据流量催生了各式各样的负载均衡产品，很多专业的负载均衡硬件提供了很好的功能，但却价格不菲，这使得负载均衡软件大受欢迎，nginx 就是其中的一个，在 linux 下有 Nginx、LVS、Haproxy 等等服务可以提供负载均衡服务，而且 Nginx 提供了几种分配方式(策略)： </p><p><strong>1、轮询（默认）</strong></p><p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</p><p><strong>2weight</strong></p><p>weight 代表权,重默认为 1,权重越高被分配的客户端越多</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">upstream server_pool&#123; <br>server 192.168.5.21 weight=10; <br>server 192.168.5.22 weight=10; <br>&#125;<br></code></pre></td></tr></table></figure><p><strong>3 ip_hash</strong></p><p>每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。 </p><p>192.168.111.1第一次访问返回的是8080，然后客户端就记住了这个ip的哈希，下一次这个地址访问的时候就就还会分配8080，除非ip地址发生改变。</p><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs roboconf">upstream server_pool&#123; <br><span class="hljs-attribute">ip_hash; </span><br><span class="hljs-attribute">server 192.168.5.21</span>:80; <br><span class="hljs-attribute">server 192.168.5.22</span>:80; <br>&#125;<br></code></pre></td></tr></table></figure><p><strong>4 fair（第三方）</strong></p><p>按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs axapta">upstream server_pool&#123; <br><span class="hljs-keyword">server</span> <span class="hljs-number">192.168</span><span class="hljs-number">.5</span><span class="hljs-number">.21</span>:<span class="hljs-number">80</span>; <br><span class="hljs-keyword">server</span> <span class="hljs-number">192.168</span><span class="hljs-number">.5</span><span class="hljs-number">.22</span>:<span class="hljs-number">80</span>; <br>fair; <br>&#125;<br></code></pre></td></tr></table></figure><h2 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h2><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728170642833.png" alt="image-20210728170642833"></p><p>通过 location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏 览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源 设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可， 所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件， 不建议使用 Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一 个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码304， 如果有修改，则直接从服务器重新下载，返回状态码 200。 </p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728171624602.png" alt="image-20210728171624602"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728190018462.png" alt="image-20210728190018462"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728195305969.png" alt="image-20210728195305969"></p><h2 id="Nginx高可用"><a href="#Nginx高可用" class="headerlink" title="Nginx高可用"></a>Nginx高可用</h2><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728195432791.png" alt="image-20210728195432791"></p><p>2、配置高可用的准备工作 </p><ul><li>（1）需要两台服务器 192.168.200.130 和 192.168.200.133</li><li>（2）在两台服务器安装 nginx </li><li>（3）在两台服务器安装 keepalived </li></ul><p>3、在两台服务器安装 keepalived </p><p>（1）使用 yum 命令进行安装 </p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">yum <span class="hljs-keyword">install</span> keepalived –y <br></code></pre></td></tr></table></figure><p>（2）安装之后，在 etc 里面生成目录 keepalived，有文件 keepalived.conf</p><p>修改配置文件：</p><p>把etc/keepalived文件改为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs shell">! Configuration File for keepalived<br><br>global_defs &#123;<br> notification_email &#123;<br>acassen@firewall.loc<br>failover@firewall.loc<br>sysadmin@firewall.loc<br> &#125;<br> notification_email_from Alexandre.Cassen@firewall.loc<br> smtp_server 192.168.200.130<br> smtp_connect_timeout 30<br> router_id LVS_DEVEL<br>&#125;<br>vrrp_script chk_http_port &#123;<br> script &quot;/usr/local/src/nginx_check.sh&quot;<br> interval 2 #（检测脚本执行的间隔）<br> weight 2<br>&#125;<br><br>vrrp_instance VI_1 &#123;<br> state MASTER # 备份服务器上将 MASTER 改为 BACKUP <br> interface ens33 //网卡<br> virtual_router_id 51 # 主、备机的 virtual_router_id 必须相同<br> priority 100 # 主、备机取不同的优先级，主机值较大，备份机值较小<br> advert_int 1<br> authentication &#123;<br> auth_type PASS<br> auth_pass 1111<br> &#125;<br> virtual_ipaddress &#123;<br> 192.168.200.50 // VRRP H 虚拟地址<br> &#125; <br> &#125;<br></code></pre></td></tr></table></figure><p>把usr/local/src增加脚本文件：</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728202818137.png" alt="image-20210728202818137"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>A=`ps -C nginx –no-header |wc -l`<br>if [ $A -eq 0 ];then<br>    /usr/local/nginx/sbin/nginx<br>    sleep 2<br>    if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then<br>        killall keepalived<br>    fi<br>fi<br></code></pre></td></tr></table></figure><p>开启两个nginx</p><p>开启两个服务器keepalived</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">systemctl <span class="hljs-literal">start</span> keepalived.service<br></code></pre></td></tr></table></figure><p>测试：</p><p>输入192.168.200.50，会出现ngixn欢迎页</p><p>把192.168.200.130宕机</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arduino">关闭nginx<br>systemctl stop keepalived.service<br></code></pre></td></tr></table></figure><p>会发现还有nginx欢迎页</p><h2 id="Nginx原理"><a href="#Nginx原理" class="headerlink" title="Nginx原理"></a>Nginx原理</h2><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728204016774.png" alt="image-20210728204016774"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728204031602.png" alt="image-20210728204031602"></p><p><strong>master-workers 的机制的好处</strong> </p><p>首先，对于每个 worker 进程来说，独立的进程，<strong>不需要加锁，所以省掉了锁带来的开销</strong>，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master 进程则很快启动新的worker 进程。当然，worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险。</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs axapta">（<span class="hljs-number">1</span>）可以使用 nginx –s reload 热部署，利用 nginx 进行热部署操作<br>（<span class="hljs-number">2</span>）每个 woker 是独立的进程，如果有其中的一个 woker 出现问题，其他 woker 独立的，继续进行争抢，实现请求过程，不会造成服务中断<br><br><br><br>即worker1拿到了一开始抢到了任务，然后修改了配置文件，这个时候worker1不会过来争抢，其他的worker来争抢，当worker2抢到了<span class="hljs-keyword">client</span>之后，会加载配置文件，这个时候会把worker1的配置修改，完成热部署<br></code></pre></td></tr></table></figure><p><strong>需要设置多少个</strong> <strong>worker</strong></p><p>Nginx 同 redis 类似都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话下。每个 worker 的线程可以把一个 cpu 的性能发挥到极致。所以 worker 数和服务器的 cpu数相等是最为适宜的。设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来的损耗。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728204802714.png" alt="image-20210728204802714"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210728205113869.png" alt="image-20210728205113869"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RockerMQ 笔记</title>
    <link href="/2021/07/25/RockerMQ-%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/07/25/RockerMQ-%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h1><h2 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h2><p><strong>1 消息（Message）</strong></p><p>消息是指，消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。</p><p><strong>2 主题（</strong>Topic）</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725205453022.png" alt="image-20210725205453022"></p><p>Topic表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。 topic:message 1:n message:topic 1:1</p><p>一个生产者可以同时发送多种Topic的消息；而一个消费者只对某种特定的Topic感兴趣，即只可以订阅和消费一种Topic的消息。 producer:topic 1:n consumer:topic 1:1</p><p><strong>3 标签（</strong>Tag）</p><p>为消息设置的标签，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。Topic是消息的一级分类，Tag是消息的二级分类。</p><p>Topic：货物</p><p>tag=上海</p><p>tag=江苏tag=浙江</p><p>——- 消费者 —– </p><p>topic=货物 tag = 上海</p><p>topic=货物 tag = 上海|浙江</p><p>topic=货物 tag = *</p><p><strong>4 队列（</strong>Queue）</p><p>存储消息的物理实体。一个Topic中可以包含多个Queue，每个Queue中存放的就是该Topic的消息。一个Topic的Queue也被称为一个Topic中消息的分区（Partition）（相当于包装骨头的袋子）。一个Topic的Queue中的消息只能被一个消费者组中的一个消费者消费。一个Queue中的消息不允许同一个消费者组中的多个消费者同时消费。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725210345016.png" alt="image-20210725210345016"></p><p>在学习参考其它相关资料时，还会看到一个概念：分片（Sharding）。分片不同于分区。在RocketMQ中，分片指的是存放相应Topic的Broker。每个分片中会创建出相应数量的分区，即Queue，每个Queue的大小都是相同的。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725205610004.png" alt="image-20210725205610004"></p><p><strong>5 消息标识（</strong>MessageId/Key）</p><p>RocketMQ中每个消息拥有唯一的MessageId，且可以携带具有业务标识的Key，以方便对消息的查询。不过需要注意的是，MessageId有两个：在生产者send()消息时会自动生成一个MessageId（msgId)，当消息到达Broker后，Broker也会自动生成一个MessageId(offsetMsgId)。</p><p>msgId、offsetMsgId与key都称为消息标识。</p><p>msgId：由producer端生成，其生成规则为：producerIp + 进程pid + MessageClientIDSetter类的ClassLoader的hashCode +当前时间                 + AutomicInteger自增计数器</p><p>offsetMsgId：由broker端生成，其生成规则为：brokerIp + 物理分区的offset（Queue中的偏移量）</p><p>key：由用户指定的业务相关的唯一标识</p><h2 id="二、系统架构"><a href="#二、系统架构" class="headerlink" title="二、系统架构"></a>二、系统架构</h2><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725211733002.png" alt="image-20210725211733002"></p><p>RocketMQ架构上主要分为四部分构成：</p><ul><li>Producer：消息的发送者；举例：发信者</li><li>Consumer：消息接收者；举例：收信者</li><li>Broker：暂存和传输消息；举例：邮局</li><li>NameServer：管理Broker；举例：各个邮局的管理机构</li><li>Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者可以订阅一个或者多个Topic消息</li><li>Message Queue：相当于是Topic的分区；用于并行发送和接收消息</li></ul><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726091134133.png" alt="image-20210726091134133"></p><p><strong>1 Producer</strong></p><p>消息生产者，负责生产消息。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。</p><blockquote><p>例如，业务系统产生的日志写入到<em>MQ</em>的过程，就是消息生产的过程 </p><p>再如，电商平台中用户提交的秒杀请求写入到<em>MQ</em>的过程，就是消息生产的过程 </p></blockquote><p>RocketMQ中的消息生产者都是以生产者组（Producer Group）的形式出现的。生产者组是同一类生产者的集合，这类Producer发送相同Topic类型的消息。一个生产者组可以同时发送多个主题的消息。</p><p><strong>2 Consumer</strong></p><p>消息消费者，负责消费消息。一个消息消费者会从Broker服务器中获取到消息，并对消息进行相关业务处理。</p><blockquote><p>例如，<em>QoS</em>系统从<em>MQ</em>中读取日志，并对日志进行解析处理的过程就是消息消费的过程。 </p><p>再如，电商平台的业务系统从<em>MQ</em>中读取到秒杀请求，并对请求进行处理的过程就是消息消费的 </p><p>过程。</p></blockquote><p>RocketMQ中的消息消费者都是以消费者组（Consumer Group）的形式出现的。消费者组是同一类消费者的集合，这类Consumer消费的是同一个Topic类型的消息。消费者组使得在消息消费方面，实现==负载均衡==（将一个Topic中的不同的Queue平均分配给同一个Consumer Group的不同的Consumer，注意，并不是将消息负载均衡）和==容错==（一个Consmer挂了，该Consumer Group中的其它Consumer可以接着消费原Consumer消费的Queue）的目标变得非常容易。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725213400661.png" alt="image-20210725213400661"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725213557574.png" alt="image-20210725213557574"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725212439827.png" alt="image-20210725212439827"></p><p>消费者组中Consumer的数量应该小于等于订阅Topic的Queue数量。如果超出Queue数量，则多出的Consumer将不能消费消息。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210725212453169.png" alt="image-20210725212453169"></p><p>不过，一个Topic类型的消息可以被多个消费者组同时消费。</p><blockquote><p>注意， </p><p><em>1</em>）消费者组只能消费一个<em>Topic</em>的消息，不能同时消费多个<em>Topic</em>消息 </p><p><em>2</em>）一个消费者组中的消费者必须订阅完全相同的<em>Topic</em></p><p>相当于一个订单号只能给处理库存的消费者组的一个来消费，如果两个消费库存的消费者消费了，库存就会-2</p><p>但是一个订单号可以被处理库存和增加销量两个不同的消费者组来消费</p></blockquote><p><strong>3 Name Server</strong></p><p><strong>功能介绍</strong></p><p>NameServer是一个Broker与Topic路由的注册中心,消息发送给NameServer，再转发给broker，相当于dubbo中的注册中心，支持Broker的动态注册与发现。RocketMQ的思想来自于Kafka，而Kafka是依赖了Zookeeper的。所以，在RocketMQ的早期版本，即在MetaQ v1.0与v2.0版本中，也是依赖于Zookeeper的。从MetaQ v3.0，即RocketMQ开始去掉了Zookeeper依赖，使用了自己的NameServer。主要包括两个功能：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">Broker管理：接受Broker集群的注册信息并且保存下来作为路由信息的基本数据；提供心跳检测机制，检查Broker是否还存活。</span><br><span class="hljs-keyword"></span><br>路由信息管理：每个NameServer中都保存着<span class="hljs-keyword">Broker集群的整个路由信息和用于客户端查询的队列信息。Producer和Conumser通过NameServer可以获取整个Broker集群的路由信息，从而进行消息的投递和消费。</span><br></code></pre></td></tr></table></figure><p><strong>路由注册</strong></p><p>NameServer通常也是以集群的方式部署，不过，NameServer是无状态的，即NameServer集群中的各个节点间是无差异的，各节点间相互不进行信息通讯，nameserver集群中的每个nameserver互不相通。那各节点中的数据是如何进行数据同步的呢？在Broker节点启动时，轮询NameServer列表，与每个NameServer节点建立长连接，发起注册请求。在NameServer内部维护着⼀个Broker列表，用来动态存储Broker的信息。</p><blockquote><p>注意，这是与其它像<em>zk</em>、<em>Eureka</em>、<em>Nacos</em>等注册中心不同的地方。 </p><p>这种<em>NameServer</em>的无状态方式，有什么优缺点： </p><p>优点：<em>NameServer</em>集群搭建简单，扩容简单。 </p><p>缺点：对于<em>Broker</em>，必须明确指出所有<em>NameServer</em>地址。否则未指出的将不会去注册。也正因 为如此，<em>NameServer</em>并不能随便扩容。因为，若<em>Broker</em>不重新配置，新增的<em>NameServer</em>对于 <em>Broker</em>来说是不可见的，其不会向这个<em>NameServer</em>进行注册。</p></blockquote><p>Broker节点为了证明自己是活着的，为了维护与NameServer间的长连接，会将最新的信息以心跳包的方式上报给NameServer，每30秒发送一次心跳。心跳包中包含 BrokerId、Broker地址(IP+Port)、 Broker名称、Broker所属集群名称等等。NameServer在接收到心跳包后，会更新心跳时间戳，记录这个Broker的最新存活时间。</p><p><strong>路由发现</strong></p><p>RocketMQ的路由发现采用的是Pull模型。当Topic路由信息出现变化时，NameServer不会主动推送给</p><p>客户端，而是客户端定时拉取主题最新的路由。默认客户端每30秒会拉取一次最新的路由</p><blockquote><p>扩展： </p><p><em>1</em>）<em>Push</em>模型：推送模型。其实时性较好，是一个<em>“</em>发布*-<em>订阅</em>”*模型，需要维护一个长连接。而</p><p>长连接的维护是需要资源成本的。该模型适合于的场景： </p><p>实时性要求较高</p><p><em>Client</em>数量不多，<em>Server</em>数据变化较频繁 </p><p><em>2</em>）<em>Pull</em>模型：拉取模型。存在的问题是，实时性较差。 </p><p><em>3</em>）<em>Long Polling</em>模型：长轮询模型。其是对<em>Push</em>与<em>Pull</em>模型的整合，充分利用了这两种模型的优 </p><p>势，屏蔽了它们的劣势。</p></blockquote><p><strong>客户端NameServer选择策略</strong></p><blockquote><p>这里的客户端指的是<em>Producer</em>与<em>Consumer</em></p></blockquote><p>客户端在配置时必须要写上NameServer集群的地址，那么客户端到底连接的是哪个NameServer节点呢？客户端首先会生产一个随机数，然后再与NameServer节点数量取模，此时得到的就是所要连接的节点索引，然后就会进行连接。如果连接失败，则会采用round-robin策略，逐个尝试着去连接其它节点。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">首先采用的是随机策略进行的选择，失败后采用的是轮询策略。 <br></code></pre></td></tr></table></figure><blockquote><p>扩展：<em>Zookeeper Client</em>是如何选择<em>Zookeeper Server</em>的？ </p><p>简单来说就是，经过两次<em>Shufæe</em>，然后选择第一台<em>Zookeeper Server</em>。 </p><p>详细说就是，将配置文件中的<em>zk server</em>地址进行第一次<em>shufæe</em>，然后随机选择一个。这个选择出 </p><p>的一般都是一个<em>hostname</em>。然后获取到该<em>hostname</em>对应的所有<em>ip</em>，再对这些<em>ip</em>进行第二次 </p><p><em>shufæe</em>，从<em>shufæe</em>过的结果中取第一个<em>server</em>地址进行连接。</p></blockquote><p><strong>4 Broker</strong></p><p><strong>功能介绍</strong></p><p>Broker充当着消息中转角色，负责存储消息、转发消息。Broker在RocketMQ系统中负责接收并存储从</p><p>生产者发送来的消息，同时为消费者的拉取请求作准备。Broker同时也存储着消息相关的元数据，包括</p><p>消费者组消费进度偏移offset(消费到哪了)、主题、队列等。</p><blockquote><p><em>Kafka 0.8</em>版本之后，<em>offset</em>是存放在<em>Broker</em>中的，之前版本是存放在<em>Zookeeper</em>中的。</p></blockquote><p><strong>模块构成</strong></p><p>下图为Broker Server的功能模块示意图。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726091631157.png" alt="image-20210726091631157"></p><p><strong>集群部署</strong></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726091708936.png" alt="image-20210726091708936"></p><p>为了增强Broker性能与吞吐量，Broker一般都是以集群形式出现的。各集群节点中可能存放着相同Topic的不同Queue。不过，这里有个问题，如果某Broker节点宕机，如何保证数据不丢失呢？</p><p>其解决方案是，将每个Broker集群节点进行横向扩展，即将Broker节点再建为一个HA集群，解决单点问题。</p><p>Broker节点集群是一个主从集群，即集群中具有Master与Slave两种角色。Master负责处理读写操作请求，Slave负责对Master中的数据进行备份。当Master挂掉了，Slave则会自动切换为Master去工作。所以这个Broker集群是主备集群。一个Master可以包含多个Slave，但一个Slave只能隶属于一个Master。 Master与Slave 的对应关系是通过指定相同的BrokerName、不同的BrokerId 来确定的。BrokerId为0表 示Master，非0表示Slave。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726101329664.png" alt="image-20210726101329664"></p><p><strong>5</strong> <strong>工作流程</strong></p><p><strong>具体流程</strong></p><p>1）启动NameServer，NameServer启动后开始监听端口，等待Broker、Producer、Consumer连接。</p><p>2）启动Broker时，Broker会与所有的NameServer建立并保持长连接，然后每30秒向NameServer定时发送心跳包。</p><p>3）发送消息前，可以先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，当然，在创建Topic时也会将Topic与Broker的关系写入到NameServer中。不过，这步是可选的，也可以在发送消息时自动创建Topic。 </p><p>4）Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取路由信息，即当前发送的Topic消息的Queue与Broker的地址（IP+Port）的映射关系，确定消息是发送给哪个broker，再确定发给哪个queue，这样就可以i实现负载均衡。然后根据算法策略从队选择一个Queue，<strong>与队列所在的Broker建立长连接从而向Broker发消息</strong>。当然，在获取到路由信息后，Producer会首先将路由信息缓存到本地，再每30秒从NameServer更新一次路由信息。</p><p>5）Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取其所订阅Topic的路由信息，然后根据算法策略从路由信息中获取到其所要消费的Queue，然后直接跟Broker建立长连接，开始消费其中的消息。Consumer在获取到路由信息后，同样也会每30秒从NameServer更新一次路由信息。不过不同于Producer的是，Consumer还会向Broker发送心跳，以确保Broker的存活状态。</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs lasso">Topic的创建模式<br><br>手动创建Topic时，有两种模式：<br><br>集群模式：该模式下创建的Topic在该集群中，所有Broker中的<span class="hljs-built_in">Queue</span>数量是相同的。<br><br>Broker模式：该模式下创建的Topic在该集群中，每个Broker中的<span class="hljs-built_in">Queue</span>数量可以不同。<br><br>自动创建Topic时，默认采用的是Broker模式，会为每个Broker默认创建<span class="hljs-number">4</span>个<span class="hljs-built_in">Queue</span>。 <br></code></pre></td></tr></table></figure><p><strong>读/写队列</strong></p><p>从物理上来讲，读/写队列是同一个队列。所以，不存在读/写队列数据同步问题。读/写队列是逻辑上进行区分的概念。一般情况下，读/写队列数量是相同的。</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs tap">例如，创建Topic时设置的写队列数量为8，读队列数量为4，此时系统会创建8个Queue，分别是0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>4<span class="hljs-number"> 5 </span>6 7。Producer会将消息写入到这8个队列，但Consumer只会消费0<span class="hljs-number"> 1 </span>2 3这4个队列中的消息，4<span class="hljs-number"> 5 </span>6 7中的消息是不会被消费到的。<br></code></pre></td></tr></table></figure><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs tap">再如，创建Topic时设置的写队列数量为4，读队列数量为8，此时系统会创建8个Queue，分别是0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>4<span class="hljs-number"> 5 </span>6 7。Producer会将消息写入到0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>这4个队列，但Consumer只会消费0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>4<span class="hljs-number"> 5 </span>6 7这8个队列中的消息，但是4<span class="hljs-number"> 5 </span>6 7中是没有消息的。此时假设Consumer Group中包含两个Consuer，Consumer1消 费0<span class="hljs-number"> 1 </span>2 3，而Consumer2消费4<span class="hljs-number"> 5 </span>6 7。但实际情况是，Consumer2是没有消息可消费的。<br></code></pre></td></tr></table></figure><p>也就是说，当读/写队列数量设置不同时，总是有问题的。那么，为什么要这样设计呢？</p><p>其这样设计的目的是为了，方便Topic的Queue的缩容。</p><blockquote><p>例如，原来创建的Topic中包含16个Queue，如何能够使其Queue缩容为8个，还不会丢失消息？可以动态修改写队列数量为8，读队列数量不变。此时新的消息只能写入到前8个队列，而消费都消费的却是16个队列中的数据。当发现后8个Queue中的消息消费完毕后，就可以再将读队列数量动态设置为8。整个缩容过程，没有丢失任何消息。</p></blockquote><p>perm用于设置对当前创建Topic的操作权限：2表示只写，4表示只读，6表示读写。</p><p>三、安装</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726151811409.png" alt="image-20210726151811409"></p><p>C:\Windows\System32\drivers\etc\hosts</p><p>2.vim etc/hostmane修改主机名叫rocketmqos01</p><p>3.vim etc/sysconfig/network-scripts/ifcfg-net33</p><p>修改ip地址为192.168.200.163</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726192045125.png" alt="image-20210726192045125"></p><p>下载<a href="https://rocketmq.apache.org/release_notes/release-notes-4.9.0/">https://rocketmq.apache.org/release_notes/release-notes-4.9.0/</a></p><p>解压到/opt目录</p><p>修改配置文件：<img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726192216003.png" alt="image-20210726192216003"></p><p><strong>可视化工具使用</strong>：</p><p>可视化工具：也是broke的客户端，和provide和consumer一样需要指定name server的地址，才能获得broke的路由信息</p><p>1.修改propersity的配置文件：</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726193512342.png" alt="image-20210726193512342"></p><p>2.修改pom文件加入如下依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>javax.xml.bind<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jaxb-api<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.3.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.sun.xml.bind<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jaxb-impl<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.3.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span> <br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.sun.xml.bind<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jaxb-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.3.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>javax.activation<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>activation<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><p>3.打包，再console文件下下cmd，执行完成后进入target目录，找到该文件</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726194508035.png" alt="image-20210726194508035"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726194401246.png" alt="image-20210726194401246"></p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">mvn clean package -<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Dmaven</span>.</span></span>test.skip=<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>4.复制生成的jar文件，复制到其他目录,运行</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">java</span> -jar rocket-console-ng-<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.jar<br></code></pre></td></tr></table></figure><p>5.浏览器输入localhost:7000</p><h2 id="三、集群搭建理论"><a href="#三、集群搭建理论" class="headerlink" title="三、集群搭建理论"></a>三、集群搭建理论</h2><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726203211496.png" alt="image-20210726203211496"></p><p><strong>1</strong> <strong>数据复制与刷盘策略</strong></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726203238294.png" alt="image-20210726203238294"></p><p><strong>复制策略</strong></p><p>复制策略是Broker的Master与Slave间的数据同步方式。分为同步复制与异步复制：</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">同步复制：消息写入<span class="hljs-literal">master</span>后，<span class="hljs-literal">master</span>会等待<span class="hljs-literal">slave</span>同步数据成功后才向producer返回成功ACK<br><br>异步复制：消息写入<span class="hljs-literal">master</span>后，<span class="hljs-literal">master</span>立即向producer返回成功ACK，无需等待<span class="hljs-literal">slave</span>同步数据成功<br><br>异步复制策略会降低系统的写入延迟，RT变小，提高了系统的吞吐量<br></code></pre></td></tr></table></figure><p><strong>刷盘策略</strong></p><p>刷盘策略指的是broker中消息的落盘方式，即消息发送到broker内存后消息持久化到磁盘的方式。分为</p><p>同步刷盘与异步刷盘：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">同步刷盘：当消息持久化到<span class="hljs-keyword">broker的磁盘后才算是消息写入成功。</span><br><span class="hljs-keyword"></span><br>异步刷盘：当消息写入到<span class="hljs-keyword">broker的内存后即表示消息写入成功，无需等待消息持久化到磁盘。</span><br></code></pre></td></tr></table></figure><blockquote><p><em>1</em>）异步刷盘策略会降低系统的写入延迟，<em>RT</em>变小，提高了系统的吞吐量 </p><p><em>2</em>）消息写入到<em>Broker</em>的内存，一般是写入到了<em>PageCache</em> </p><p><em>3</em>）对于异步 刷盘策略，消息会写入到<em>PageCache</em>后立即返回成功<em>ACK</em>。但并不会立即做落盘操 </p><p>作，而是当<em>PageCache</em>到达一定量时会自动进行落盘。</p></blockquote><p><strong>2 Broker集群模式</strong></p><p>根据Broker集群中各个节点间关系的不同，Broker集群可以分为以下几类：</p><p><strong>单Master</strong></p><p>只有一个broker（其本质上就不能称为集群）。这种方式也只能是在测试时使用，生产环境下不能使用，因为存在单点问题。</p><p><strong>多Master</strong> </p><p>broker集群仅由多个master构成，不存在Slave。==同一Topic的各个Queue会平均分布在各个master节点上==。</p><p>负载均衡：同一topic的各个queue会平均分配到同一个消费者组的不同消费者身上</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">优点：配置简单，单个<span class="hljs-literal">Master</span>宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高；<br><br>缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅（不可消费），消息实时性会受到影响。<br><br>以上优点的前提是，这些<span class="hljs-literal">Master</span>都配置了RAID磁盘阵列。如果没有配置，一旦出现某<span class="hljs-literal">Master</span>宕机，则会发生大量消息丢失的情况。 <br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726204441815.png" alt="image-20210726204441815"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210726204740196.png" alt="image-20210726204740196"></p><p><strong>多Master多Slave模式异步复制</strong></p><p>broker集群由多个master构成，每个master又配置了多个slave（在配置了RAID磁盘阵列的情况下，一个master一般配置一个slave即可）。master与slave的关系是主备关系，即master负责处理消息的读写请求，而slave仅负责消息的备份与master宕机后的角色切换。</p><p>异步复制即前面所讲的复制策略中的异步复制策略，即消息写入master成功后，master立即向producer返回成功ACK，无需等待slave同步数据成功。该模式的最大特点之一是，当master宕机后slave能够自动切换为master。不过由于slave从master的同步具有短暂的延迟（毫秒级），所以当master宕机后，这种异步复制方式可能会存在少量消息的丢失问题。</p><blockquote><p><em>Slave</em>从<em>Master</em>同步的延迟越短，其可能丢失的消息就越少 </p><p>对于<em>Master</em>的<em>RAID</em>磁盘阵列，若使用的也是异步复制策略，同样也存在延迟问题，同样也可能</p><p>会丢失消息。但<em>RAID</em>阵列的秘诀是微秒级的（因为是由硬盘支持的），所以其丢失的数据量会 </p><p>更少。 </p></blockquote><p><strong>多Master多Slave模式同步双写</strong></p><p>该模式是多Master多Slave模式的同步复制实现。所谓同步双写，指的是消息写入master成功后，master会等待slave同步数据成功后才向producer返回成功ACK，即master与slave都要写入成功后才会返回成功ACK，也即双写。该模式与异步复制模式相比，优点是消息的安全性更高，不存在消息丢失的情况。但单个消息的RT略高，从而导致性能要略低（大约低10%）。</p><p>该模式存在一个大的问题：对于目前的版本，Master宕机后，Slave不会自动切换到Master。</p><p><strong>最佳实践</strong></p><p>一般会为Master配置RAID10磁盘阵列，然后再为其配置一个Slave。即利用了RAID10磁盘阵列的高效、安全性，又解决了可能会影响订阅的问题。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs crmsh"><span class="hljs-number">1</span>）RAID磁盘阵列的效率要高于<span class="hljs-literal">Master</span>-<span class="hljs-literal">Slave</span>集群。因为RAID是硬件支持的。也正因为如此， 所以RAID阵列的搭建成本较高。<br><span class="hljs-number">2</span>）多<span class="hljs-literal">Master</span>+RAID阵列，与多<span class="hljs-literal">Master</span>多<span class="hljs-literal">Slave</span>集群的区别是什么？ <br><br><br>多<span class="hljs-literal">Master</span>+RAID阵列，其仅仅可以保证数据不丢失，即不影响消息写入，但其可能会影响到消息的订阅。但其执行效率要远高于多<span class="hljs-literal">Master</span>多<span class="hljs-literal">Slave</span>集群，因为raid是硬件支持，写入速度较快<br>多<span class="hljs-literal">Master</span>多<span class="hljs-literal">Slave</span>集群，其不仅可以保证数据不丢失，也不会影响消息写入。其运行效率要低 于多<span class="hljs-literal">Master</span>+RAID阵列<br></code></pre></td></tr></table></figure><h2 id="四、集群搭建实战"><a href="#四、集群搭建实战" class="headerlink" title="四、集群搭建实战"></a>四、集群搭建实战</h2><p>这里要搭建一个双主双从异步复制的Broker集群。为了方便，这里使用了两台主机来完成集群的搭建。 这两台主机的功能与broker角色分配如下表。</p><table><thead><tr><th>序号</th><th>主机号/ip</th><th>IP</th><th>功能</th><th>Broker角色</th></tr></thead><tbody><tr><td>01</td><td>rocketmq02</td><td>192.168.200.134</td><td>NameServer+Broker</td><td>Master1 + Slave2</td></tr><tr><td>02</td><td>rocketmq03</td><td>192.168.200.135</td><td>NameServer+Broker</td><td>Master2 + Slave1</td></tr></tbody></table><p>1.克隆一个rockertmq02，hostname为rocketmq02，ip地址为192.168.200.134，在windows的systems32文件修改host文件配置</p><p>2.进入下图的命令：</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727144729355.png" alt="image-20210727144729355"></p><p>3.修改这两个文件</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727144840604.png" alt="image-20210727144840604"></p><p>4.修改broker-a.properties为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 指定整个broker集群的名称，或者说是RocketMQ集群的名称</span><br>brokerClusterName=DefaultCluster<br><span class="hljs-meta">#</span><span class="bash"> 指定master-slave集群的名称。一个RocketMQ集群可以包含多个master-slave集群</span><br>brokerName=broker-a<br><span class="hljs-meta">#</span><span class="bash"> master的brokerId为0</span><br>brokerId=0<br><span class="hljs-meta">#</span><span class="bash"> 指定删除消息存储过期文件的时间为凌晨4点</span><br>deleteWhen=04<br><span class="hljs-meta">#</span><span class="bash"> 指定未发生更新的消息存储文件的保留时长为48小时，48小时后过期，将会被删除</span><br>fileReservedTime=48<br><span class="hljs-meta">#</span><span class="bash"> 指定当前broker为异步复制master</span><br>brokerRole=ASYNC_MASTER<br><span class="hljs-meta">#</span><span class="bash"> 指定刷盘策略为异步刷盘</span><br>flushDiskType=ASYNC_FLUSH<br><span class="hljs-meta">#</span><span class="bash"> 指定Name Server的地址</span><br>namesrvAddr=192.168.200.134:9876;192.168.200.135:9876<br></code></pre></td></tr></table></figure><p>5.修改broker-b-s.properties的内容为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">brokerClusterName=DefaultCluster<br><span class="hljs-meta">#</span><span class="bash"> 指定这是另外一个master-slave集群</span><br>brokerName=broker-b<br><span class="hljs-meta">#</span><span class="bash"> slave的brokerId为非0</span><br>brokerId=1<br>deleteWhen=04<br>fileReservedTime=48<br><span class="hljs-meta">#</span><span class="bash"> 指定当前broker为slave</span><br>brokerRole=SLAVE<br>flushDiskType=ASYNC_FLUSH<br>namesrvAddr=192.168.200.134:9876;192.168.200.135:9876<br><span class="hljs-meta">#</span><span class="bash"> 指定Broker对外提供服务的端口，即Broker与producer与consumer通信的端口。默认10911。由于当前主机同时充当着master1与slave2，<span class="hljs-comment"># 而前面的master1使用的是默认端口。这里需要将这两个端口加以区分，以区分出master1与slave2</span></span><br>listenPort=11911<br><span class="hljs-meta">#</span><span class="bash"> 指定消息存储相关的路径。默认路径为~/store目录。由于当前主机同时充当着master1与slave2，master1使用的是默认路径，这里就需要</span><br><span class="hljs-meta">#</span><span class="bash"> 再指定一个不同路径</span><br>storePathRootDir=~/store-s<br>storePathCommitLog=~/store-s/commitlog<br>storePathConsumeQueue=~/store-s/consumequeue<br>storePathIndex=~/store-s/index<br>storeCheckpoint=~/store-s/checkpoint<br>abortFile=~/store-s/abort<br></code></pre></td></tr></table></figure><p>6 克隆生成rocketmq03 克隆rocketmq02主机，并修改配置。指定主机名为rocketmq03。 </p><p>7 重复上述过程，一直进入到该目录，修改这两个文件</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727145457592.png" alt="image-20210727145457592"></p><p>8 修改broker-b.properties为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">brokerClusterName=DefaultCluster<br>brokerName=broker-b<br>brokerId=0<br>deleteWhen=04<br>fileReservedTime=48<br>brokerRole=ASYNC_MASTER<br>flushDiskType=ASYNC_FLUSH<br>namesrvAddr=192.168.200.134:9876;192.168.200.135:9876<br></code></pre></td></tr></table></figure><p> 9 修改broker-a-s.properties为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">brokerClusterName=DefaultCluster<br>brokerName=broker-a<br>brokerId=1<br>deleteWhen=04<br>fileReservedTime=48<br>brokerRole=SLAVE<br>flushDiskType=ASYNC_FLUSH<br>namesrvAddr=192.168.200.134:9876;192.168.200.135:9876<br>listenPort=11911<br>storePathRootDir=~/store-s<br>storePathCommitLog=~/store-s/commitlog<br>storePathConsumeQueue=~/store-s/consumequeue<br>storePathIndex=~/store-s/index<br>storeCheckpoint=~/store-s/checkpoint<br>abortFile=~/store-s/abort<br></code></pre></td></tr></table></figure><p>10 启动集群</p><p>启动NameServer集群 分别启动rocketmqOS1与rocketmqOS2两个主机中的NameServer。启动命令完全相同</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arcade">nohup sh bin/mqnamesrv &amp;<br>tail -f ~<span class="hljs-regexp">/logs/</span>rocketmqlogs/namesrv.log<br></code></pre></td></tr></table></figure><p><strong>启动两个Master</strong></p><p> 分别启动rocketmqOS1与rocketmqOS2两个主机中的broker master。注意，它们指定所要加载的配置 文件是不同的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">rocketmq02启动这个：192.168.200.134</span><br>nohup sh bin/mqbroker -c conf/2m-2s-async/broker-a.properties &amp;<br>tail -f ~/logs/rocketmqlogs/broker.log<br><span class="hljs-meta"></span><br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash">rocketmq03启动这个：192.168.200.135</span><br>nohup sh bin/mqbroker -c conf/2m-2s-async/broker-b.properties &amp;<br>tail -f ~/logs/rocketmqlogs/broker.log<br></code></pre></td></tr></table></figure><p><strong>启动两个Slave</strong></p><p>分别启动rocketmqOS1与rocketmqOS2两个主机中的broker slave。注意，它们指定所要加载的配置文 件是不同的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">rocketmq02启动这个：192.168.200.134</span><br>nohup sh bin/mqbroker -c conf/2m-2s-async/broker-b-s.properties &amp;<br>tail -f ~/logs/rocketmqlogs/broker.log<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash">rocketmq03启动这个：192.168.200.135</span><br>nohup sh bin/mqbroker -c conf/2m-2s-async/broker-a-s.properties &amp;<br>tail -f ~/logs/rocketmqlogs/broker.log<br></code></pre></td></tr></table></figure><p>查看启动是否成功</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">jps命令<br></code></pre></td></tr></table></figure><p>遇到的问题：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs awk">卸载jdk，再重新安装jdk，下载的jdk版本为jdk1.<span class="hljs-number">8.0</span>_301<br>https:<span class="hljs-regexp">//</span>blog.csdn.net<span class="hljs-regexp">/zhwyj1019/</span>article<span class="hljs-regexp">/details/</span><span class="hljs-number">81103531</span><br>追加的内容：<br>export JAVA_HOME=<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/java/</span>jdk1.<span class="hljs-number">8.0</span>_301/<br>export JRE_HOME=<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/java/</span>jdk1.<span class="hljs-number">8.0</span>_301/jre<br>export PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/java/</span>jdk1.<span class="hljs-number">8.0</span>_301/bin<br>export CLASSPATH=.<span class="hljs-regexp">/:/u</span>sr<span class="hljs-regexp">/local/</span>java<span class="hljs-regexp">/jdk1.8.0_301/</span>lib:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/java/</span>jdk1.<span class="hljs-number">8.0</span>_301<span class="hljs-regexp">/jre/</span>lib<br><br>mqadmin要添加的内容（资料中）：<br><span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/java/</span>jdk1.<span class="hljs-number">8.0</span>_301<span class="hljs-regexp">/jre/</span>lib/ext <br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727163658242.png" alt="image-20210727163658242"></p><p><strong>第3章 RocketMQ工作原理</strong></p><p>一、消息的生产</p><p><strong>1</strong> <strong>消息的生产过程</strong> </p><ul><li>Producer可以将消息写入到某Broker中的某Queue中，其经历了如下过程：</li><li>Producer发送消息之前，会先向NameServer发出获取消息Topic的路由信息的请求</li><li>NameServer返回该Topic的路由表及Broker列表</li><li>Producer根据代码中指定的Queue选择策略，从Queue列表中选出一个队列，用于后续存储消息</li><li>Produer对消息做一些特殊处理，例如，消息本身超过4M，则会对其进行压缩</li><li>Producer向选择出的Queue所在的Broker发出RPC请求，将消息发送到选择出的Queue </li></ul><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">路由表：实际是一个Map，key为Topic名称，value是一个QueueData实例列表。QueueData并不 是一个Queue对应一个QueueData，而是一个<span class="hljs-keyword">Broker中该Topic的所有Queue对应一个 </span>QueueData。即，只要涉及到该Topic的<span class="hljs-keyword">Broker，一个Broker对应一个QueueData。QueueData中</span><br><span class="hljs-keyword"></span>包含<span class="hljs-keyword">brokerName。简单来说，路由表的key为Topic名称，value则为所有涉及该Topic的 </span><span class="hljs-keyword">BrokerName列表。</span><br><span class="hljs-keyword"></span><br><br><span class="hljs-keyword">Broker列表：其实际也是一个Map。key为brokerName，value为BrokerData。一个Broker对应一 </span>个<span class="hljs-keyword">BrokerData实例，对吗？不对。一套brokerName名称相同的Master-Slave小集群对应一个 </span><span class="hljs-keyword">BrokerData。BrokerData中包含brokerName及一个map。该map的key为brokerId，value为该 </span><span class="hljs-keyword">broker对应的地址。brokerId为0表示该broker为Master，非0表示Slave。</span><br></code></pre></td></tr></table></figure><p><strong>2 Queue选择算法</strong></p><p>对于无序消息，其Queue选择算法，也称为消息投递算法，常见的有两种：</p><p><strong>轮询算法</strong></p><p>默认选择算法。该算法保证了每个Queue中可以均匀的获取到消息。</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lasso">该算法存在一个问题：由于某些原因，在某些Broker上的<span class="hljs-built_in">Queue</span>可能投递延迟较严重。从而导致Producer的缓存队列中出现较大的消息积压，影响消息的投递性能<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727183014347.png" alt="image-20210727183014347"></p><p><strong>最小投递延迟算法</strong></p><p> 该算法会统计每次消息投递的时间延迟，然后根据统计出的结果将消息投递到时间延迟最小的Queue。 如果延迟相同，则采用轮询算法投递。该算法可以有效提升消息的投递性能。</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lasso">该算法也存在一个问题：消息在<span class="hljs-built_in">Queue</span>上的分配不均匀。投递延迟小的<span class="hljs-built_in">Queue</span>其可能会存在大量<br>的消息。而对该<span class="hljs-built_in">Queue</span>的消费者压力会增大，降低消息的消费能力，可能会导致MQ中消息的堆<br>积。<br></code></pre></td></tr></table></figure><p>二、消息的存储 </p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727185356478.png" alt="image-20210727185356478"></p><p>RocketMQ中的消息存储在本地文件系统中，这些相关文件默认在当前用户主目录下的store目录中。</p><ul><li>abort：该文件在Broker启动后会自动创建，正常关闭Broker，该文件会自动消失。若在没有启动</li><li>Broker的情况下，发现这个文件是存在的，则说明之前Broker的关闭是非正常关闭。</li><li>checkpoint：其中存储着commitlog、consumequeue、index文件的最后刷盘时间戳</li><li>commitlog：其中存放着commitlog文件，而消息是写在commitlog文件中的</li><li>conæg：存放着Broker运行期间的一些配置数据</li><li>consumequeue：其中存放着consumequeue文件，队列就存放在这个目录中</li><li>index：其中存放着消息索引文件indexFile </li><li>lock：运行期间使用到的全局资源锁</li></ul><p><strong>1 commitlog文件</strong> </p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">说明：在很多资料中commitlog目录中的文件简单就称为commitlog文件。但在源码中，该文件 被命名为mappedFile。<br></code></pre></td></tr></table></figure><p><strong>目录与文件</strong></p><p>commitlog目录中存放着很多的mappedFile文件，当前Broker中的所有消息都是落盘到这些mappedFile文件中的。mappedFile文件大小为1G（小于等于1G），文件名由20位十进制数构成，表示当前文件的第一条消息的起始位移偏移量。</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs excel">第一个文件名一定是<span class="hljs-number">20</span>位<span class="hljs-number">0</span>构成的。因为第一个文件的第一条消息的偏移量commitlog <span class="hljs-built_in">offset</span>为<span class="hljs-number">0</span> 当第一个文件放满时，则会自动生成第二个文件继续存放消息。假设第一个文件大小是 <span class="hljs-number">1073741820</span>字节（<span class="hljs-number">1</span>G = <span class="hljs-number">1073741824</span>字节），如果没存慢就按照没存满的算，则第二个文件名就是<span class="hljs-number">00000000001073741824</span>。 以此类推，第<span class="hljs-built_in">n</span>个文件名应该是前<span class="hljs-built_in">n</span>-<span class="hljs-number">1</span>个文件大小之和。 一个Broker中所有mappedFile文件的commitlog <span class="hljs-built_in">offset</span>是连续的<br></code></pre></td></tr></table></figure><p>需要注意的是，一个Broker中仅包含一个commitlog目录，所有的mappedFile文件都是存放在该目录中的。<strong>即无论当前Broker中存放着多少Topic的消息</strong>，这些消息都是被顺序写入到了mappedFile文件中的。也就是说，<strong>这些消息在Broker中存放时并没有被按照Topic进行分类存放</strong>。</p><p>疑问：topic存放在queue中，为什么会在mappedfile中呢？</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">mappedFile文件是顺序读写的文件，所有其访问效率很高 无论是SSD磁盘还是SATA磁盘，通常情况下，顺序存取效率都会高于随机存取。<br></code></pre></td></tr></table></figure><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727192110424.png" alt="image-20210727192110424"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727185329662.png" alt="image-20210727185329662"></p><p><strong>2 consumequeue</strong></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727192646234.png" alt="image-20210727192646234"></p><p>为了提高效率，会为每个Topic在~/store/consumequeue中创建一个目录，目录名为Topic名称。在该Topic目录下，会再为每个该Topic的Queue建立一个目录，目录名为queueId。每个目录中存放着若干consumequeue文件，consumequeue文件是commitlog的索引文件，可以根据consumequeue定位到具体的消息。</p><p>consumequeue文件名也由20位数字构成，表示当前文件的第一个索引条目的起始位移偏移量。与mappedFile文件名不同的是，其后续文件名是固定的。因为consumequeue文件大小是固定不变的。</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727192608559.png" alt="image-20210727192608559"></p><p><strong>索引条目</strong></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727192855888.png" alt="image-20210727192855888"></p><p>每个consumequeue文件可以包含30w个索引条目，每个索引条目包含了三个消息重要属性：消息在mappedFile文件中的偏移量CommitLog Offset、消息长度、消息Tag的hashcode值。这三个属性占20个字节，所以每个文件的大小是固定的30w * 20字节。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">一个consumequeue文件中所有消息的Topic一定是相同的。但每条消息的<span class="hljs-keyword">Tag</span>可能是不同的<br></code></pre></td></tr></table></figure><p><strong>3</strong> <strong>对文件的读写</strong></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727193304547.png" alt="image-20210727193304547"></p><p><strong>消息写入</strong></p><p>一条消息进入到Broker后经历了以下几个过程才最终被持久化。</p><ul><li><p>Broker根据queueId，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset </p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">queueId再produce发送时候根据负载均衡已经指定，根据queudId可以知道<span class="hljs-built_in">offset</span>已经到哪（有记录）<br></code></pre></td></tr></table></figure></li><li><p>将queueId、queueOffset等数据，与消息一起封装为消息单元将消息单元写入到commitlog</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727194300714.png" alt="image-20210727194300714"></p></li><li><p>同时，形成消息索引条目</p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210727194332274.png" alt="image-20210727194332274"></p></li><li><p>将消息索引条目分发到相应的consumequeue</p></li></ul><p><strong>消息拉取</strong></p><p>当Consumer来拉取消息时会经历以下几个步骤：</p><p>1.Consumer获取到其要消费消息所在Queue的消费偏移量offset，计算出其要消费消息的消息offset</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">消费<span class="hljs-built_in">offset</span>即消费进度，consumer对某个Queue的消费<span class="hljs-built_in">offset</span>，即消费到了该Queue的第几 条消息 消息<span class="hljs-built_in">offset</span> = 消费<span class="hljs-built_in">offset</span> + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>2.Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue、消息offset及消息Tag。 </p><p>3.Broker计算在该consumequeue中的queueOffset。 </p><p>4.从该queueOffset处开始向后查找第一个指定Tag的索引条目。</p><p>5.解析该索引条目的前8个字节，即可定位到该消息在commitlog中的commitlog offset</p><p>6.从对应commitlog offset中读取消息单元，并发送给Consumer</p><p><strong>性能提升</strong></p><ul><li><p>RocketMQ中，无论是消息本身还是消息索引，都是存储在磁盘上的。其不会影响消息的消费吗？当然不会。其实RocketMQ的性能在目前的MQ产品中性能是非常高的。因为系统通过一系列相关机制大大提升了性能。</p></li><li><p>首先，RocketMQ对文件的读写操作是通过mmap零拷贝进行的，将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率。</p></li><li><p>其次，consumequeue中的数据是顺序存放的，还引入了PageCache的预读取机制，使得对consumequeue文件的读取几乎接近于内存读取，即使在有消息堆积情况下也不会影响性能。</p></li></ul><p><em>PageCache</em>机制，页缓存机制，是<em>OS</em>对文件的缓存机制，用于加速对文件的读写操作。一般来 说，程序对文件进行顺序读写的速度几乎接近于内存读写速度，主要原因是由于<em>OS</em>使用 <em>PageCache</em>机制对读写访问操作进行性能优化，将一部分的内存用作<em>PageCache</em>。 </p><ul><li><p>写操作：<em>OS</em>会先将数据写入到<em>PageCache</em>中，随后会以异步方式由<em>pdæush</em>（<em>page dirty æush)</em> 内核线程将<em>Cache</em>中的数据刷盘到物理磁盘</p></li><li><p>读操作：若用户要读取数据，其首先会从<em>PageCache</em>中读取，若没有命中，则<em>OS</em>在从物理磁 盘上加载该数据到<em>PageCache</em>的同时，也会顺序对其相邻数据块中的数据进行预读取。</p></li></ul><p>RocketMQ中可能会影响性能的是对commitlog文件的读取。因为对commitlog文件来说，读取消息时会产生大量的随机访问，而随机访问会严重影响性能。不过，如果选择合适的系统IO调度算法，比如设置调度算法为Deadline（采用SSD固态硬盘的话），随机读的性能也会有所提升。</p>]]></content>
    
    
    
    <tags>
      
      <tag>RocketMQ</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux随笔</title>
    <link href="/2021/07/25/linux%E9%9A%8F%E7%AC%94/"/>
    <url>/2021/07/25/linux%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717090500369.png" alt="image-20210717090500369"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717090557301.png" alt="image-20210717090557301"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717092156240.png" alt="image-20210717092156240"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717092247954.png" alt="image-20210717092247954"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717092720926.png" alt="image-20210717092720926"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717095757720.png" alt="image-20210717095757720"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717100119467.png" alt="image-20210717100119467"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717100309244.png" alt="image-20210717100309244"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717100405216.png" alt="image-20210717100405216"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717113249234.png" alt="image-20210717113249234"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717150213076.png" alt="image-20210717150213076"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717150233956.png" alt="image-20210717150233956"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717152017549.png" alt="image-20210717152017549"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717152735900.png" alt="image-20210717152735900"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717153127445.png" alt="image-20210717153127445"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717155050422.png" alt="image-20210717155050422"></p><p><img src="https://gitee.com/wang-yang11/ingcache/raw/master/ingcache/image-20210717160904588.png" alt="image-20210717160904588"></p>]]></content>
    
    
    
    <tags>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
